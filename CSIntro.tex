\section{Introduction}

One major hurdle in developing robust applications is getting them to run reliably across all of the environments on
which they may be installed.  In an increasingly diverse software ecosystem it is not uncommon for problematic
differences to appear between these environments.  Whether it happens because of a lack of adherence to standards or
developer error, the result is the same: software written to run in multiple environments falls victim to the
differences between those environments.  These can easily go unnoticed due to the infeasibility of testing software
across every combination of hardware and software on which it is expected to run.   The typical approach to eliminating
faults of any kind in an application is to test its functionality through a number of tests to ensure it acts as
expected.  In the case of issues that arise from an application's environment it is not possible to enumerate and test
for an acceptable amount of faults due to the variety of hardware and software systems that can make up the environment.

This problem is of particular concern in the context of today's highly network dependent applications.  With the
explosion of mobile computing and services provided via the internet, applications that are completely reliant on
well-behaved network communication are increasingly common.  As a result a great deal of emphasis must be placed on
properly dealing with faults in these network communications.  Unfortunately, identifying these faults is difficult due
to the inability of the developer to replicate all possible application environments, exhaust a wide variety of code
paths and to ensure consistent performance.

In an attempt to remedy this situation, a wide variety of automated testing tools have been developed.  These tools
typically follow either a black-box or white-box approach.  In the case of white-box testing, the tools attempt to gain
an understanding of the application by analyzing its code, with the goal of generating inputs that execute the
application's code paths.  In the case of black-box testing, the tools simply generate inputs and present them to the
application in order to achieve a similar goal.  Both of these techniques have their advantages and disadvantages.

CrashSimulator is a single utility that can combine the best qualities of the above techniques in order to provide
developers with the confidence that their applications are reasonably free of environment-induced faults.
CrashSimulator meets this need by providing automated identification of environment-induced faults through simulated
deviations from the normal flow of system calls an application makes when interacting with its environment.  This allows
a developer to test an application as if it was running in an environment different from the one in which it is being
written. Like other white-box tools, CrashSimulator attempts to analyze an application in order to understand where it
can inject faults to best test the application.  However, unlike other tools it bypasses the application's source code
entirely --- instead relying on system call traces.  This reduces CrashSimulator's footprint by eliminating complex
programming language analysis code while still allowing insight into the application's operation.  Furthermore, because
it bases its analysis on system call traces from the application running in a real environment this analysis takes into
account the application's interactions with that environment.

CrashSimulator's analysis relies on two concepts.  The first is encoding bad system call patterns as deterministic
computation models (i.e. DFA, PDA, etc.....) Encoding behavior in this way allows us to identify the correct point to
inject failures into a given execution and to make an assessment about whether the application responded to the injected
failure correctly................

The second is deterministic replay of the application under test's system call behavior.  Replaying an earlier execution
allows us to treat these anomalous executions like test cases.  That is, they can be run in any environment simulating,
from the application's perspective, the environment we want to test the application in............
    
In short, CrashSimulator helps us find bugs faster by allowing to inject problematic behavior into an application at the
system call level.  For example, we can make a call to rename() fail with the EXDEV errno value which should force
well-behaved applications to either initiate a manual cross-device file copy procedure or fail out indicating an error.
If the application continues as if nothing is amiss, then it has failed to properly handle the anomaly (an ``unusual''
condition).

If this process is repeated many times over with multiple anomaly types and checkers it acts like a test suite.  Because
anomalies can be injected into any application that presents the appropriate opportunity, the ``tests'' that make up
this ``suite'' are applicable across applications.  This allows CrashSimulator's user to construct a suite of tests
built from all the applications they work on so it can be leveraged on any project touch.

CrashSimulator makes the following contributions: \emph{Do we need to rework contributions?}

    \begin{enumerate}
        \item{CrashSimulator is the first tool to use system call traces recorded in one environment as a basis for
            injecting faults into an application running in another environment.}
        \item{CrashSimulator is able to produce thousands of mutated system call traces per minute even when operating
            on large system call traces from complex applications.}
        \item{CrashSimulator is able to reliably identify faults that result from differences between an applications
            development environment and its deployment environment.}
        \item{CrashSimulator's efficacy can be validated by its ability to identify errors listed in the bug trackers of
            major projects and predicted by other testing tools.}
    \end{enumerate}
