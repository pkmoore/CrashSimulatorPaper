\section{Introduction}

    One major hurdle in developing robust applications is anticipating and dealing with edge conditions and faults that
    compromise an application's ability to run as intended. A common source of faults is the environment in which an
    application runs. In an increasingly diverse software ecosystem it is not uncommon for problematic differences to
    appear between different environments. Whether it happens because of a lack of adherence to standards, intentional
    divergence from the standards, or developer error, the result is the same: software written to run in multiple
    environments falls victim to the differences between those environments. These can easily go unnoticed due to the
    infeasibility of testing software across every combination of hardware and software on which it is expected to run.
    The typical approach to eliminating faults of any kind in an application is the creation of a suite of tests that
    exercise the applications functionality and ensure that it always acts appropriately. In the case of issues that
    arise from an application's environment it is not possible to enumerate and test for an acceptable amount of faults
    due to the variety of hardware and software systems that can make up the environment.

    This problem is of particular concern in the context of today's highly network dependent applications. With the
    explosion of mobile computing and ``software as a service'' products, applications that are completely reliant on
    well-behaved network communication are increasingly common. As a result a great deal of emphasis must be placed on
    properly dealing with faults in these network communications. Unfortunately, identifying these faults is difficult
    due to the inability of the developer to replicate all possible application environments and exhaust all possible
    code paths.

    In an attempt to remedy this situation, a wide variety of automated testing tools have been developed. These tools
    typically follow either a black-box or white-box approach. In the case of white-box testing, the tools attempt to
    gain an understanding of the application by analyzing its code with the goal of generating inputs that most
    completely exercise the application's code paths. In the case of black-box testing, the tools simply generate
    slightly abnormal inputs and present them to the application in order to achieve a similar goal.

    Both of these techniques have their advantages and disadvantages. CrashSimulator is a tool designed to meet this
    need by providing automated identification of environment-induced faults through simulated deviations from the
    normal flow of system calls an application makes when interacting with its environment. This allows a developer to
    test an application as if it was running in an environment different from the one in which it is being written. Like
    other white-box tools, CrashSimulator attempts to analyze an application in order to understand where it can inject
    faults.  However, unlike other tools it bypasses the application's source code entirely --- instead relying on
    system call traces.  This reduces CrashSimulator's footprint by eliminating complex programming language analysis
    code while still allowing insight into the application's operation. Furthermore, because it bases its analysis on
    system call traces from the application running in a real environment this analysis takes into account the
    application's interactions with that environment.

    During its analysis, CrashSimulator identifies faults from system call traces recorded as applications were run in a
    real-world environment. Ideally, this environment is intended to be a deployment target for the application under
    test. In this case, an application's environment refers to the hardware, software, and network setup on which the
    application is expected to run. Next, it mutates an original system call trace taken from the application under test
    based on these previous observations. Typically, this ideal run will be performed in the application's development
    environment. The mutations CrashSimulator makes are designed to induce the faults identified earlier into a run of
    the application.  Once analysis is complete, CrashSimulator runs the application under test and replays the mutated
    system call traces. The behavior of the application under test is monitored and CrashSimulator reports to the
    developer whether or not the application successfully handled the injected faults or not.

    CrashSimulator makes the following contributions:

    \begin{enumerate}
        \item{CrashSimulator is the first tool to use system call traces recorded in one environment as a basis for
            injecting faults into an application running in another environment.}
        \item{CrashSimulator is able to produce thousands of mutated system call traces per minute even when operating
            on large system call traces from complex applications.}
        \item{CrashSimulator is able to reliably identify faults that result from differences between an applications
            development environment and its deployment environment.}
        \item{CrashSimulator's efficacy can be validated by its ability to identify errors listed in the bug trackers of
            major projects and predicted by other testing tools.}
    \end{enumerate}
