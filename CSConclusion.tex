\section{Conclusion}

Minimizing the number of faults present in the applications they write is a key concern for software developers.  A
number of automated testing techniques have been created in order to meet this goal.  The most sophisticated of these
existing techniques focus on either analyzing an applications source code or machine code in order to gain an
understanding of the inputs required to exercise an applications code paths and then exercising them with the goal of
exposing faults.  These techniques focus on the application itself to the neglect of the application's environment which
can be a source of numerous faults that cannot be identified by testing the application in isolation.  To combat this
problem this work presents CrashSimulator, a tool that utilizes replay of system call traces in order to facilitate the
injection of environment-based faults into the application for testing purposes.

CrashSimulator's focus on bugs that can occur at the interace between an appication and its environment allow it to fill
a gap in the landscape of existing testing techniques.  CrashSimulator can supplement existing testing processes for an
application by providing additional ``unit tests'' that cover areas that are often missed.

CrashSimulator's key features, operating on system calls and analysis of replayed executions set it apart from other
tools in the space.  By operating at the system call level CrashSimulator is able to avoid the complexities around
language specific processing while still having a level of control not present in tools that generate inputs in a
blackbox fashion.  CrashSimulator's method of testing using replayed execution is novel and provides a few unique
opportunities.  Performing its analysis on a replayed execution of an application allows CrashSimulator to remove the
filesystem, network, etc. dependancies of the application under test allowing removing many of the complications of
testing applications across different environments.  It also allows CrashSimulator to easily influence execution in ways
that are advantageous for testing.

We have shown that CrashSimulator is able to find a class of bugs that is often neglected.  The ability to take bugs
from a variety of sources, transform them into generic computational models, and use them to analyze the execution of a
variety of applications showed that the same sorts of mistakes were being made across many different projects.
Specifically, CrashSimulator found bugs in Python's shutils, mmv............ Additionally, CrashSimulator found bugs
from a different class in gpg........

    \subsubsection{Other Considerations}

    During the course of implementation pain points arose around some of the technologies chosen.  For example, the
    potential exists for an improved implementation of CrashSimulator that uses something other than Ptrace for process
    manipulation.  Building CrashSimulator on top of a virtual machine might provide more reliable control.
    Additionally, there are challenges around using system call traces as the basis of the replayed execution.  One such
    disadvantage is the size of the traces can grow dramatically in situations where an application is reading and
    writing a great deal of data.  Potentially, a system call trace could be many times the size of the total amount of
    data written.  Additionally, strace is imperfect in the way it captures data from some system calls and the
    presentation of this data is difficult to process programatically.  There may be more suitable ways of logging the
    system calls an application makes.
    