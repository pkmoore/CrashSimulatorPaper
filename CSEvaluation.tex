\section{Evaluation}

    This work hopes to answer the following questions about CrashSimulator's operation:

        \begin{enumerate}
            \item{Is CrashSimulator successful in identifying flaws in new and existing applications?}
            \item{Is CrashSimulator able to execute tests in a performant manner?}
        \end{enumerate}

    \subsection{Execution Performance}

        One key attribute of successful testing tools is that they be able to complete their tests in a timely manner.
        If a tool takes too long to complete its tests users will be less likely to run it frequently, or at all,
        reducing the tools overall usefulness dramatically. To this end, the performance of CrashSimulator was evaluated
        in order to determine whether or not it was able to complete its test executions in an acceptable time frame.

        \subsubsection{Evaluation Against Sample Programs}

        Each of the following evaluations eamines the completion times for 20 consecurive executions of the specified
        application in both native and replay execution modes.  Multiple conseuritve executions were used for two
        reasons.  First, a single execution in either mode completes so quickly for the applications in question as to
        be nearly indistinguishable from the other mode.  Second, multiple executions somewhat contros for varying
        conditions like filesystem activity or network latency that can vary between individual executions.

            \begin{table}[H]
                \scriptsize{}
                \begin{tabular}{l  l  l  l}
                    \toprule{}
                        Execution Description & Native Eecution & Replay Execution\\
                        network\_speedtest & 0.024 & 2.407 \\
                        filesystem\_speedtest & 0.038 & 2.604 \\
                        mv file across disks & 0.016 & 2.995 \\
                    \bottomrule{}
                \end{tabular}
            \end{table}

        \paragraph{Discussion on network\_speedtest}

        Sample application opens a TCP connection toan already running listener (netcat), sends a message, and
        exits. For simple applications like this, native execution is significantly faster than replay execution...

        \paragraph{Discussion on filesystem\_speedtest}

        This ample application create a new file with open(), writes a message to it, closes the file descriptor, and
        exit()'s. This test is particularly meaningful as it replicates a pattern of system calls that is used for in
        all sorts of applications in Linux...
            
    \subsection{Bugs Identified in Major Applications}

        \subsubsection{Identification of Known Bugs}

        Another way we evaluated the efficacy of CrashSimulator was on its ability to detect known bugs as recorded in
        the bug trackers of major open source software projects.

            \paragraph{Race Condition in shutil.copy, shutil.copy2, shutil.copyfile - Bug ID\# 15100}
              
            This bug describes a situation where the described functions in the shutil package do not perform the checks
            necessary to prevent a race condition around the process of copying a file from one filesystem to another --
            a situation that prevents the use of the safer {\tt rename()} system call.  CrashSimulator is able to detect this
            issue in replayed executions of python applications that make use of these functions by identifying the
            applications failure to use {\tt fstat()} to verify that a file has not changed between the time the file was
            first checked with {\tt stat()} and when it was open()'d at the start of the copy process.

        \subsubsection{Identification of Unknown Bugs}

        \subsubsection{Cross-Device Move Bugs}

        In Linux, the rename() system call will only move a file if the source and destination are on the same device.
        This means that moving a file from a directory structure location on one storage device to a directory structure location on
        another device must be handled on a case-by-case basis by any application that relies on this operation.  With
        this in mined, we examined the process by which the coreutils {\tt mv}command handles this task and constructed
        computational models that can determine whether or not a replayed execution of an application has performed all
        the necessary steps to successfully carry out a cross device move.  Next, these models were employed during
        replayed executions of the listed applications in order to determine whether or not their copy operation is correct.

        \paragraph{Verify Destination is not Target of Source}

        In this condition, CrashSimulator confirms whether or not the application under test performs a check to ensure
        that the source file name is not a symlink pointing to the destination file name.  If this check is not
        performed, loss of data is possible due to removal or overwriting of the destination during the copy process
        resulting in the source symlink pointing to nothing.

        \paragraph{Preserve Extended File Attributes}

        In this condition, CrashSimulator determines whether or not the application under test correctly preserves
        extended file attributes by reading them from the source file and applying them to the destination file prior to
        removing the source file.  Extended file attributes are often used to store information such as the original
        providance of the file (i.e. downloaded from the internet, received from an trusted vendor, etc.).  Loss of
        these attributes can result in security issues. For example, Apple's Gatekeeper relies on extended file
        attributes to prevent applications downloaded untrusted developers from being executed without user
        confirmation.

        \paragraph{Ensure Source is not Replaced Between Check and Copy}

        This is an example of a classic race condition.  In this case, CrashSimulator examines whether or not the
        appication under test makes uses of fstat() to ensure that the inode number of the file being copied has not
        changed between initial examination with a stat()-like call and the eventual copy.  

        \paragraph{Preserve Timestamp and Mode}

        Truely copying a file means preserving the metadata of the file as well as its contents.  In this condition,
        CrashSimulator ascertains whether or not the application under test restores the appropriate timestamps and
        modeline to the destination file after (or before) its contents have been copied. 

        \paragraph{Move Block Device Across Disks}

        Many applications fail to examine the nature of a file before engaging in a manual, cross-disk copy process.  In
        situations where the source is a special file such as /dev/urandom.  If an application fails to detect this
        situation, the typical steps in a manual copy process could result in the application filling the destination
        destination device, consuming available memory, or simply hanging indefinitely as it attempts to read in the
        full contents of an effectively infinite-sized file.

\begin{figure*}[t]
 %           \begin{table}%[t]
                \scriptsize{}
                \begin{tabular}{l l l l l l | l}
                \toprule{}
                  Condition & mv & mmv & shutils & rust & boost::copyfile & Mode\\
                  Verify Destination is not Target of Source & Yes & Yes & No & ??? & No & Passive\\
                  Preserve Extended File Attributes & Yes & No & No & No & No & Passive\\
                  File Replaced Between Check and Copy & Yes & No & No & Yes & No & Passive\\
                  Preserve Timestamp and Mode & Yes & No & Yes & Yes & No & Passive\\
                  Move Directory Into Itself & Yes & Yes & Yes & N/A, won't move directories & N/A, won't move directories & Passive\\
                  Move Block Device Across Disks & Yes & Yes & Yes & No & No & Injected\\
                \bottomrule{}
                \end{tabular}
 %           \end{table}
\end{figure*}

        \subsubsection{Non-Regular File Bugs}

        These bugs involve modifying the executions of applications that work with regular files such that a call to
        {\tt stat()} or {\tt lstat()} indicates that the file in question is instead some sort of special file.  Well behaved
        applications should verify that the files they are accessing are regular files before processing them.  Many
        applications make the assumption that they will only be used to process regular files.  Encountering special
        files tends to induce a denial of service condition that in certain circumstances, such as an automated
        environment, can halt a scripted process or workflow.

            \begin{table*}[t]
                \scriptsize{}
                \begin{tabular}{l  l  l  | l}
                \toprule{}
                  Application & Condition Tested & Correct Response & Mode\\
                  gnu-gpg & Import link to /dev/urandom as key file & \textbf{no}, application hangs & Passive\\
                  vim & Inject S\_IFIFO as file type in stat64 call & \textbf{no}, attempts open as regular file & Active\\
                  nano & Inject S\_IFIFO as file type in stat64() call & \textbf{no}, attempts open as regular file & Active\\
                  wget & Inject S\_ICHR as file type in stat64() & \textbf{no}, attempts open as regular file & Active\\
                \bottomrule{}
                \end{tabular}
            \end{table*}


    \subsection{Limitations}

        The current implementation of CrashSimulator has the following limitations that could be addressed by future work.

        \paragraph{Coupling to Architecture}

        As some faults injected by CrashSimulator require low level access to the test system's hardware or operating
        system data structures there exists some degree of coupling between CrashSimulator and these components. One
        area of expansion for CrashSimulator is support for more processor architectures and more operating systems.
        CrashSimulator's test launcher as been designed in such a way that these improvements should be trivial to plug
        in once they have been implemented.

        \paragraph{Multi-threaded or Multi-process Applications}

        The current implementation cannot correctly replay applications that rely on multi-threading or
        multi-processing.  Is due to two factors.  First, the replay tool must be able to force some pre-determined
        order onto the threads or processes in order to prevent situations where the execution portion of a replay ends
        up requesting system calls in a different order than was recorded in the system call trace the system is
        attempting to replay.  Second, the tool needs to be able to correctly monitor multiple processes. {\tt Ptrace}
        may have appropriate facilities for this task but they were not explored for this version of the tool.

        \paragraph{Multi-Platform Tracing Tool}

        While there are system call tracing tools available for most of the major operating systems available today
        there is not one tool that works across all of them.  This means that if CrashSimulator is going to be able to
        to work with traces from a given operating system, it will require specific parsing logic for the output of the
        tool used to record the traces.  Additionally, CrashSimulator requires that the tracing tools record all data
        passed into a system call and all data returned from the system call either as a return value or as some block
        of memory written into the calling process's memory.  It is possible that some system call tracing tools do not
        support this level of detail.
